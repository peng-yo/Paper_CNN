#+author: Chunyou Peng
#+date: [2023-03-8]

* 多语言手写数字识别，使用鲁棒深度神经网络与迁移学习相结合
** 摘要
数字识别在创建自动化系统如邮寄地址分类和车牌识别方面起着重要的作用。如今，具有识别多种语言能力的数字识别系统由于国际通讯和交易不断增长而具有极高的价值，这尤其在多语言国家中有多种语言同时使用的情况下更为突出。因此，手写数字识别比印刷数字识别更具挑战性，因为手写有着不同而且复杂的风格。因此，开发多语言手写系统被认为是一个重要而有争议的问题。我们通过提出基于强大卷积神经网络的语言无关模型，来解决这个问题。我们的模型包括语言识别和数字识别，旨在处理多脚本图像的识别。我们在所提出的系统中使用了迁移学习来提高图像质量和识别性能。进行了广泛的实验，以验证语言和数字识别过程的有效性。该系统被测试使用了六种不同的语言。结果显示，在识别各种语言及其相关数字方面，平均准确率高达99.8%。所提出模型的鲁棒性和设计程序为识别其他语言的手写数字创建了一种经济实惠的扩展。
** 引言
手写数字的识别已经引起了计算机视觉和图像处理社区的很多兴趣。一个主要原因是因为在各种应用中，数字识别在自动分类邮件、自动处理银行支票、自动车牌识别、老年历史手写文件数字化等方面起着关键作用[1-4]。这个研究课题属于手写字符识别的广泛领域。与印刷数字或字符识别相比，手写数字和字符识别都受到不同书写风格、笔画等问题的困扰。手写识别系统旨在将手写字符转换为可机器读取的格式。在考虑到数字时代的当前进展的情况下，建立稳健和准确的其他语言的脚本识别系统也是必要的。在当前的十年里，各种机器学习技术已经被用于手写数字识别，包括随机森林（RF）、k最近邻（kNN）、决策树（DT）、隐马尔可夫模型（HMM）、局部相似性和多样性保存辨别投影（LSDDP）、模糊算法等[1,3,5-7]。一些研究者将这些机器学习技术与图像处理方法相结合，以增加识别准确性和系统性能。现有的研究已经使用了不同的特征，例如Gabor滤波器、定向梯度直方图（HOG）、离散余弦变换（DCT）、小波等，与不同的分类器相结合。深度学习的出现引起了对提高手写识别系统性能的更高期望。深度学习在众多机器学习应用中已经展现出有前途的突破。因此，一些工作聚焦于为手写字符识别开发相关技术[8]。这种范式转变也扩展到了手写数字识别，并得益于聚类计算和GPU的适应以及深度学习架构的更好性能。在最近几年中，引入了各种形式的深度神经网络，其中包括循环神经网络（RNN）、卷积神经网络、长短时记忆（LSTM）网络等。虽然有关手写数字的单一脚本（一种语言）的识别的文献很丰富，但很少有研究对多脚本手写数字识别进行了研究[9]。以前的相关研究已经考虑了两个主要策略来解决这个问题。一种策略是首先独立考虑每一种语言，然后将每个单独的语言的识别应用于每个单独的语言。在Pal等人提出的一项工作中，提出了一种改进的基于二次分类器的结构，用于六种流行印度脚本的离线手写数字识别[10]。另一个有趣的策略是将所有脚本组装并馈入单个模型进行识别。这样，要识别的类的数量将乘以所使用的语言的数量。在这个类别的大多数研究中，尝试通过融合相似形状的类来减少类的数量，从而提高性能[11]。换句话说，那些数字形状相对相似的数字被合并成一个类。然而，当类的数量超过十个时，基于这种方法的技术将受到一些局限和低性能问题的影响。
在本研究中，我们开发和提出了三个主要贡献：1）我们提出了一种新型级联多语言方法，消除了当类别数量增加时性能低下的现有缺点。为了解决这个问题，先应用语言识别模块来识别输入的手写图像，然后自动为相关数字选择适当的模型进行分类；2）我们提出了一个新型的鲁棒CNN模型，具有特殊的识别率，既适用于输入图像的语言识别，也适用于数字识别。提出的模型可以识别多种语言的手写数字；3）我们使用了迁移学习，配备了自动编码器，来提高在接收识别阶段之前的低分辨率图像的质量；4）通过使用不同语言的六个手写数据库对提出的模型进行评估，即英语、卡纳达语、乌尔都语、波斯语、阿拉伯语和中文，这些数据库具有显著的书写风格多样性；5）虽然在所提出的模型中支持多种语言，但其精度比单语言模型更高，这显示了所提出方法的卓越性能。
本文的其余部分将按照这个顺序进行。相关工作回顾在第2节中介绍。在第3节中描述了所提出的模型。性能评估和实验结果在第4节中给出，随后在第5节中给出结论性的评论。

** 2. 相关工作
本节概述了手写数字识别的相关工作，包括基于手工特征、传统分类器、深度神经网络、稀疏表示、转移学习及其组合的方法。
*** 2.1 经典方法
用于手写数字识别的传统分类方法之一是支持向量机。在[12]中，从输入图像中提取出数字的垂直和水平边缘以及方向，然后与Freeman链码组合成了一个很好的特征集合，用于支持向量机分类器的输入。这种特征提取方法避免了对数字的归一化需求，最终提高了识别性能。在[13]中，针对波斯语和阿拉伯语字母和数字的手写字符识别提出了一种基于分形编码的方法。作者利用字符之间的相似性设计了多层感知机（MLP）作为分类器，对数字识别达到了91.37%的分类率。 在[14]中进行的手写数字识别的前沿工作之一是基于模糊模型的。作者从使用Box方法得到的归一化距离的特征中导出了一些模糊集。对印地语和英语数字，分别报道了95%和98.4%的识别率。在[15]中，使用混合特征集提出了一种手写数字识别方法，并进行了比较分析。在这项研究中，特征集由多种特征提取方法组成，如Box方法、平均值、标准偏差和重心。使用浅层神经网络对CHARS74手写数字数据库进行分类。 Dash等人在基于形状分析的研究中[16]利用了人类感知用于手写数字识别。他们提出了一种形状分解方法，将数字根据其形状分成几个部分，然后对提取的部分进行分类。该方法已在四种脚本上进行了评估，即Odiya、Bangla、Arabic和英语。

*** 2.2 深度学习方法

在过去的十年中，深度学习已经成为各种模式分类应用的主流方法[17]，尤其在手写数字识别方面[18,19]。在相关的工作之一[18]中，使用具有两个连续特征提取阶段的神经网络，实现并测试了MNIST基准数据库。结果非常有前途，展示了在这种情况下使用深度网络的有效性。在[20]中，提出了一种新的多尺度卷积神经网络，用于提取与手写数学表达式（包括数字）有关的空间分类特征。通过使用全局最大池化和全局注意力池化的组合训练CNN，改善了分类性能。Shopon et al. [19]使用深度卷积神经网络对英语和孟加拉文手写数字进行分类。他们通过应用数据增强阶段，将训练图像转换为块状效果，提高了识别准确率。虽然这项研究考虑了两种语言，但他们的方法应分别适用于这些语言。
在[21]中，提出了一种神经网络架构，用于识别古吉拉特语脚本的数字。他们的方法基于多层前向神经网络进行手写数字分类。作者在预处理阶段应用了细化和倾斜校正，以提高性能。最终的平均识别率为82%，并不是非常高。在[22]中，为了分类中国手写数字，提出了一个具有最小层数的定制化CNN。与更深层数和更大尺寸的网络（如GoogLeNet和MobileNetV2）相比，表现优秀。

*** 2.3 转移学习方法

转移学习是一种机器学习方法，它通过开发现有模型来处理新任务。它已广泛应用于许多应用程序，例如行为识别、图像记忆性预测以及手写数字识别。研究人员主要使用转移学习来减轻访问大规模数据库的限制。在[23]中，采用了一种转移学习方法，基于多层感知器和卷积神经网络模型，对五个手写数字数据集（藏文、阿拉伯文、孟加拉文、天城文和泰卢固文）共享特征提取过程进行了识别。作者发现，转移学习可以显著降低深度学习模型的训练时间，并略微降低了识别准确率。[24]中研究了使用转移学习对历史手写文档进行分析的方法。转移学习用于从具有可用标准参考的异构数据集中识别特征，并与没有标准参考的新数据集共享公共属性。这是为了跳过耗时的手动标准部分创建过程。这项研究表明，当训练基于各种数据集的组合（如RIMES、Georges Washington和Los Esposalles）时，转移学习可用于转录意大利喜剧剧名的手写标题任务。在最近的一项研究中，使用ResNet50架构训练了超深度神经网络，来实施多类图像分类。[25]这种方法基于转移学习，使用各种隐藏层来分类手写数字。在这种方法中，不同类别的识别精度由纪元确定。在该研究中，MNIST数据库获得了最高的识别率，达到了99%。

*** 2.4 稀疏学习方法

还有一类基于学习的方法，称为字典学习，最初用于稀疏数据表示。这些方法已经迅速扩展到模式分类和归类问题[26]。在这方面，[27]提出了一种字典学习方法来识别中文手写数字，作者通过引入一种新的字典学习方法来对15个中文数字进行分类，提高了其识别的可辨性。为了在转换域中提供高层次的特征表示，[28]提出了一个无监督特征学习过程。此外，主成分分析（PCA）被用作后处理方案，以转换从无监督特征学习中获得的过完备字典。这项工作的目的是减少无监督字典学习中基数的数量，以便实时应用。[29]提出了一种基于Fisher鉴别准则的字典学习方法，用于图像分类。学习到的字典结构化分类为主题词标签的列。该研究在USPS英文手写数据库中报告的最佳识别错误率为2.89％。[30]提出了一种用于分类人脸和手写图像的新型稀疏非负逼近方法。作者提出了一个凸稀疏编码问题，然后使用过完备的DCT字典来对手写图像进行分类。使用MNIST数据库得到的分类准确度为94.52％。

*** 2.5综合方法

Yan等人[31]利用遗传算法（GA）提出了一个优化的神经网络模型，用于手写数字识别。他们利用GA优化和设计神经网络的结构、权重、阈值、训练比率和动量因子。Chen等人[32]提出了一种自适应的分数阶反向传播（BP）神经网络，用于手写数字识别。他们提出的系统是竞争进化算法和分数阶梯度下降学习机制的组合。这种算法在MNIST英文数据库上进行了测试，并取得了卓越的性能。最近的一篇论文[33]在英文手写数字上组合了深度学习和字典学习。作者使用一个多层框架，通过奇异值分解在多层CNN模型下实现了超过99％的准确度。Pramanik等人[34]提出了一个能够识别Devanagari、Bangla、Odiya和Telugu四种印度脚本手写数字的系统。他们的方法基于卷积神经网络（CNN）和预训练网络。他们的研究分别对每种语言进行了实验。为了减少由于形状相似而可能出现的错误分类，两种语言（即Bangla和Odia）被混合并作为一个具有更多课程的语言。此外，类似形状的数字也被融合，导致了总共19个类别的分类问题。[35]提出了一种针对邮政编码分类的多脚本识别方法。作者试图将四个具有类似形状的脚本的数字特征结合起来。他们考虑到拉丁（英语）、德瓦纳加里、孟加拉和阿拉伯（乌尔都），总共有25个类别。他们实施了基于四叉树的图像分区进行特征提取。然后将提取的特征输入SVM分类器以识别25个手写数字。Gupta和Bag [9]最近提出了一种独立于脚本的手写数字识别方法。他们使用了来自多种印度和非印度脚本的数据库进行测试。他们的方法是一种基于类的CNN模型，避免了融合类似形状的类别以提高性能。[36]最近报道了对多语言手写数字识别的深层CNN进行定量分析。在这项工作中，分析了10种最先进的深层CNN方法在印度次大陆常用语言中的表现。作者得出结论认为，考虑到准确度和计算时间，Inception-v4方法较为优越。最近推出了最大的多语言手写数字数据库MNIST-MIX [37]，可以看作是由多种不同来源的阿拉伯语、孟加拉语、德瓦纳加里语、英语、波斯语、卡纳达语、瑞典语、泰卢固语、藏语和乌尔都语组成的英文MNIST数字数据库的扩展版。在将这些语言组合时，应用了各种数据处理技术，以使所有数据样本保持一致。在这项研究中，应用预训练的LeNet模型的结果显示了约90％的平均识别准确性。
** 3. 具体措施
本节中，我们描述了处理输入手写图像的提议方法的不同阶段。该模型的核心是一个深度卷积神经网络，可对输入的手写图像进行分类。由于问题的多语言性质，模型应该能够捕捉每种语言中存在的各种特征。为了更精确，我们先建立一个初步模型，用于处理三种具有不同结构的语言，分别是中文、阿拉伯语和英语。在调整模型并确保高性能后，我们将模型扩展到与另外三种语言一起操作，即卡纳达语、波斯语和乌尔都语。这种设计过程得到了我们广泛实验的支持，确保了模型在任何其他语言的数字识别中的平稳发展。图1描述了提议模型的各个阶段和完整过程。正如图中所示，提议系统由两个主要阶段组成，即语言识别（LR）和数字识别（DR）。我们的目的是设计一个系统，与各种尺寸和不同语言的输入图像兼容。基于我们在许多现有数据库中的探索和观察，我们发现58×58的适度大小适用于输入图像。因此，根据原始图像的大小，我们的提议系统在需要时执行缩放操作，正如图1所示。简单地对小于58×58的图像进行上采样可能会导致图像质量下降，从而降低识别精度。为了避免这种缺点，我们使用了传输学习过程来增强该图像类别的质量，以避免降低图像质量。如前所述，提议系统在识别实际数字之前，首先识别与输入手写图像相关的语言。然后，根据所识别的语言选择适当的模型。最后，深度学习应用于输入图像，以识别其相应的类别。该模块的结构基于卷积神经网络，对各种图像分类任务显示出非常有效的性能。

本节的其余部分中，我们介绍用于这项研究的手写数字数据库。然后，更详细地解释了LR和DR块的不同步骤。最后，将解释所提出的深度神经网络模型的结构以及传输学习技术。

*** 3.1 数据库

在这项研究中，考虑了与六种不同语言相关的数据库，以解决我们提出的模型的多语言特征。我们考虑使用成熟的英语（USPS [38]）和阿拉伯数字数据库（MADBase [39]）来评估我们的方法。 USPS数据库以灰度图像的形式包含7291个数字0-9的训练样本和2007个测试样本。同样，MADBase包括60,000个数字0-9的训练样本和10,000个测试样本。这两个数据库的样本图像如图2a和b所示。此外，使用一个公开可用的数据库[27]，其中包含道绅士手写数字，收集者为英国纽卡斯尔大学的研究人员，一些样本图像如图2c所示。本研究使用的其他三个数据库分别是卡纳达语、波斯语和乌尔都语（图3）。这些数据库属于最近收集的数据库集合，称为MNIST-MIX [37]。这三个数据库中图像的尺寸为28×28。波斯语数据库[40]是从约12,000份由本科和高中学生填写的两种类型的注册表中抽取的，包括60,000个训练样本和10,000个测试样本（图3a）。卡纳达语数据库[41]包括60,000个训练样本和10,000个测试样本，与MNIST具有相同的数据格式（图3b）。乌尔都语数据库[42]是从900多个人中收集的（图3c）。除上述数据库外，我们还使用了另一个名为HAND2020 [43]的阿拉伯数据库。该数据库有72,000个图像，可公开获取。此外，我们创建了一个英语、阿拉伯语和波斯语合成数字数据库，以评估所提出的传输学习阶段的性能。我们使用Python中的pillow库创建了这个数据库。在这个数据库中创建的图像具有单个灰度通道均为58×58。这个数据库包括10,000个合成数字0-9的样本，以灰度图像的形式呈现，使用250种不同的字体类型。

*** 3.2 语言识别

我们工作的第一个主要步骤是构建一个语言识别模型。使用该模型，我们将能够根据识别出的语言将每个图像馈送到适当的数字识别模型。以前的研究表明，将多语言脚本直接馈送到数字识别模型中并不能提供令人满意的结果，反而降低了分类精度。这种故障的主要原因之一可以归因于需要识别的类别数量的激增。解决方案之一是使用一个语言识别模型，在使用主要数字识别过程之前对不同语言的图像进行分类是必要的。因此，根据识别出的语言，将选择适当的数字识别参数适用于输入图像。在多语言系统中利用语言识别模块的另一个巨大优势是它为系统增加了可扩展性和额外的鲁棒性。没有语言识别阶段，每当使用新的脚本（具有不同语言）时，整个数字识别模型都需要从头开始进行培训。但是，通过使用语言识别模型，只需要重新培训与该特定语言相关的模型的一部分。换句话说，所提出的手写体识别系统可以在不需要重新构建整个系统的情况下扩展到更多的语言。

如本节开头所述，馈送到语言识别模型的图像的大小应该在所有不同语言中相同。这需要根据原始图像大小对输入图像进行上/下采样。我们经验性地选择这个通用大小为58×58。为了避免在放大图像时质量降低，我们建议使用传输学习技术，其中使用预预先计算的神经元权重的自编码器。有关此技术以及自编码器的结构的进一步细节详见3.5节。卷积神经网络（CNN）是一种由多个层组成的神经网络，特别用于图像识别、图像分类和图像分析。所有CNN架构中都有相同的一组操作，将输入图像馈送到一个卷积层，然后是一个最大池化层，以选择区域内的最大元素。此外，全连接层、激活函数和softmax层都参与了CNN的基本模型。由于语言识别和数字识别的输入图像的相似结构，我们在这些阶段中使用相同的模型，并在某些层次上进行了微小的差异。有关所提出的CNN技术的更多细节，请参见3.4节。

*** 3.3 数字识别
在识别输入图像的语言之后，第二个重要步骤是数字识别。在这里，我们解释了基于卷积神经网络的提出的识别模型。正如图1所示，一旦与输入图像相关联的语言被识别，我们的系统应该确定两个重要的设置。预处理和数字识别模型的选择。换句话说，LR阶段的输出决定了下一个阶段所需的参数和模型。为了开发一个成功的深度学习系统，需使用适当的预处理操作准备输入数据（如图1所示）。在DR阶段，从数据库中选取每个图像，并将其馈送到与之相关联的语言相应的一个数字识别模型中。我们的数字识别模型应该能够识别所有数据库中不同大小的图像中的数字。阿拉伯语，波斯语，乌尔都语，卡纳达语和中文数据库中的图像均具有相同的固定大小。阿拉伯语，波斯语，乌尔都语和卡纳达语数据库中所有图像的大小均为28 x 28，而中文数据库的图像大小为64 x 64。但是，英语数据库中的图像大小是可变的，因此我们将所有图像的大小更改为192 x 96。应该提到，96和192分别被认为是该数据库中所有图像的最大宽度和长度。在输入图像的预处理过程中，如果需要上采样，我们将使用上述相同的过程，使用转移学习以维护图像质量。所提出的模型的结构在所有语言的数字识别中都是相似的。但是，最终模型是根据LR模块的输出单独针对每种语言进行训练的。此外，DR的CNN模型的所有网络层在各种语言之间都相同，除了输入层需要根据先前步骤检测到的语言进行不同选择。与中文相关的模型的输出层应该具有15个输出神经元，对应数字类别的数量。利用LR模块的优点是，虽然输入图像可以是六种语言中的任何一种，但是数字识别模型会自动选择，尽管这些语言的图像大小和字符形状相对不同。如果没有语言识别系统，则最终模型必须通过对所有数据库进行训练来获得。这不是一种有效的方法，会导致问题，例如参数调整的复杂性，类数增加到64，并因此降低性能和识别准确性。利用所提出的方法中的语言识别模块的优点是首先识别输入图像的语言，然后将其转发到相应训练过的相同语言的数字识别模型。
虽然存在可以用于数字识别的预先训练的模型，例如LeNet，但我们选择为此目的设计一个新模型。根据我们的观察，预定义的网络表现不足，尤其是当多语言脚本是关注重点时。我们的目标是设计一个能够在所有语言上高精度运行的模型。以下是数字识别模块的不同步骤的说明。

*** 3.4 CNN体系结构
所提出的CNN体系结构由三种不同类型的层组成：卷积层、池化层和全连接层（也称为稠密层）。我们将详细描述这些层，如下所述：
第1层是具有ReLU激活函数的卷积层。该层的输入取决于输入图像的大小。对于LR阶段，图像的大小为N x N = 58 x 58，该层是固定的。但是，对于DR阶段，该层的大小根据在LR阶段检测到的语言进行选择。这是在图1中显示的模型选择块集中完成的。例如，在与具有N x N = 28 x 28大小图像的阿拉伯语数据库相关联的模型中，该层使用大小为F x F = 3 x 3的64个滤波器。在这层中，填充为P = 0，步幅为S = 1。这个卷积层的输出维数为26 x 26 x 64，表示具有26个行和26个列的64个矩阵。然后，ReLU激活器函数应用于这64个输出矩阵的每个矩阵中。
第2层是一个最大池化层，它接收26 x 26 x 64的上一层输出作为输入。池化大小为2 x 2，填充为P = 0，步幅为S = 2。最大池化层的输出大小为13 x 13 x 64。
第3层和第5层与第一层类似，是使用ReLU激活函数的卷积层。这两个层，如第一个卷积层一样，使用64个大小为3 x 3的滤波器，步幅为1，填充为0。第4层和第6层，如第二层，是采样层，其池化大小与第二层相同，为2 x 2，步幅为2，填充为0。
扁平化层: 在经过3层卷积层和3层采样层之后，提取的属性以输入形式给出到完全连接的层。实际上，完全连接层根据前几层提取的特征进行分类。但是，在卷积层和完全连接层之间需要一个“平坦”层，将矩阵特征转换为可输入到完全连接神经网络分类器的向量。在扁平化特征之后，它们被赋予256和128个神经元的两个完全连接的层，以及一个Sigmoid激活函数。然后，使用去除0.25％神经元的Dropout来防止过度拟合。由于使用了Keras自身的密集和卷积层，因此许多参数加权值都自动调整。所提出的模型的最后一层称为分类器层。它负责将输入图像分类为现有的类之一。对于除中文外的所有语言，分类器层具有10个神经元，而对于中文语言，它具有15个神经元。图4说明了以阿拉伯语数据库为例的所提出模型的总体架构。

*** 3.5. 转移学习
正如本节开头所述，阿拉伯数字和MNIST-MIX数据库中图像的大小比中英文数据库中的图像要小。输入图像的小尺寸是限制网络层数和开发具有更高识别能力的更深层结构的重要因素之一。如图4所示，在使用三层卷积和三层最大池化后，只剩下一个特征，需要进一步的扩展并迫使我们增加卷积层数。另一方面，我们的目标是设计一个多语种系统，能够识别不同尺寸的手写数字图像。如果图像尺寸可以放大，那么识别图像中的数字可能会更容易。然而，随着图像尺寸的增大，它们的质量会下降。这是设计有效的多语种识别系统面临的主要挑战。为了克服这个问题，我们提出使用自编码器来提高图像质量，尤其是在手写数字图像质量较低的数据库中。

转移学习通过从已学习的相关任务中转移知识来提高新任务的学习效果。它旨在通过利用源任务的知识来改进目标任务的学习。这是深度学习中的一种流行方法，其中预训练模型被用作新学习和分类任务的起点。转移学习的主要优点是学习过程可以更快，更准确，并且需要较少的训练数据。我们在转移学习模型内使用深度自编码器层，其详细信息在此处解释。我们使用英文数据库（USPS）的图像训练自编码器。由于英文数据库中的图像大小较大，我们可以使用下采样缩小图像。这些图像被视为我们的原始数据。使用原始数据的分数为0.4，创建较低分辨率图像，并将其作为自编码器的输入。自编码器在每次训练迭代中尝试增加图像的分辨率以达到原始分辨率。如图5所示，自编码器的编码器侧包括具有256和128个过滤器和3 x 3过滤器尺寸以及一个最大池化层的两层卷积。在解码器侧，使用了两个卷积层，其过滤器为128和256。此外，在自编码器层的末尾有一个上采样层。使用这种技术可以提高算法的准确性和性能。

** 实验结果
为了支持所提出系统的有效性，我们进行了广泛的实验。我们在第3.1节中介绍的所有六个手写数字数据库均用于实验。为了调整参数，我们使用了包含15,000个样本的中文数据库、包含70,000个样本的阿拉伯数据库以及包含9,000多个样本的英文数据库。我们使用Google Colab来实现和评估所提出的方法。Google Colab是一个免费而强大的协作工具，可以运行机器学习模型。它拥有强大的硬件选项，例如GPU和TPU。我们使用Python版本3.7来实现所提出的方法。接下来，我们将介绍参数调整的详细信息。最后，我们将呈现每个模块获得的结果以及整个系统的性能指标。

*** 4.1. 参数调整
为了实现具有最佳性能的模型，需要确定和调整参数，例如卷积层数量，卷积层过滤器，稠密层神经元以及优化器类型等。 卷积层数量：重要的是要找到在各种语言的所有数据库中均具有最高精度的卷积层数量。在起始点，我们使用阿拉伯数据库来评估模型并检查哪些参数可以提供最高的识别性能。这个数据库在本研究中所使用的所有数据库中具有最小的图像尺寸。因此，可以合理地声称，如果模型可以在该数据库上正确运行，则也可以成功应用于其他数据库。同时，由于阿拉伯数据库图像尺寸较小，因此可以更快地对模型进行训练。此外，对于具有大图像大小（例如中文和英文数据库）的数据库，每个卷积层后都需要添加最大池化层。主要原因是减少计算的复杂性。如第3节所述并在图4中看到的，对于阿拉伯数据库，在使用三个卷积层和三个最大池化层后，仅剩下一个特征需要再次添加到卷积层中。因此，选定最大卷积层数量为3，并在每个卷积层后添加一个最大池化层。 卷积层过滤器数量和稠密层神经元数量：为了找到适当的过滤器数量，我们测试了每个层的过滤器和神经元数量的不同值。在各种条件下，我们进行了一系列的实验，使用阿拉伯、中文和英文数据库。表1显示了具有不同数量的卷积层过滤器和稠密层神经元的数字对于阿拉伯数据库的精度。在此数据库中考虑的测试数据数量为10,000，而训练数据的数量为60,000。在这60,000个训练数据中，我们考虑20%的样本进行验证。我们还将批量大小设置为16，将epoch数设置为10。然后，使用表1中的六个最佳模型考虑使用中文和英文数据库进行训练的结果。这些结果在表2和表3中给出。 对于卷积层，我们评估了256到32之间不同值的性能以确定过滤器数量。此外，我们检查了256到64之间的多个值，以确定稠密层中神经元的数量。为了获得最终模型，我们进行了另一个实验。我们在三个阿拉伯、中文和英文数据库上测试了所有六个模型。然后，对结果进行了平均和分析。表4显示每个模型在三个数据库上的平均准确度。这个表中的结果表明每个模型具有可比性的表现。此外，正如从表4中看到的，第一个模型获得了最高的平均准确度（98.52％）。和可供最终模型考虑。此外，在表4中，不同模型的准确度之间的变化非常小，这证实了我们的模型针对参数调整模块中数据库顺序的变化具有鲁棒性。最终，表5显示了最终模型在阿拉伯、中文和英文数据库上的平均准确性。检查这些表1-5中的结果发现，64个卷积层过滤器，256个第一个稠密层和128个第二个稠密层的神经元的模型可以确定为最终模型。 优化器是可以给Keras提供的重要参数之一，它正确的选择可以增加模型的精度。Keras是一个由Python编写的深度学习API，运行在机器学习平台TensorFlow之上。它的开发重点在于实现快速的实验。表6显示了当使用以下任何优化器时，最终模型在阿拉伯数据库上的准确性：Adam、Adamax、RMSprop和SGD。如表6所示，具有Adam优化器的模型具有最佳的准确性。因此，我们使用此优化器来进行模型训练。

*** 4.2. 识别性能

正如第3节所提到的，我们的工作之一是识别与输入图像相关的语言。通过正确识别语言，我们就能够将图像转发到正确的数字识别模型。为了展示所提出方法的可扩展性，我们使用了六种语言来运行我们的模型：英语、中文、阿拉伯语、波斯语、乌尔都语和卡纳达语。因此，我们首先使用这六种不同的语言训练了系统，然后测试了我们训练好的模型。如表7所示，使用语言识别和数字识别能够维持系统的高性能。与使用单独的语言相比，所提出的多语言系统的平均准确度几乎没有下降。这种略微的精度下降原因是由于不同语言中一些数字之间的相似性。如图2b、3a和3c所示，数字“三”的图像在波斯语、阿拉伯语和乌尔都语中相对相似。因此，语言识别有时可能会失败。但是，即使语言被错误地识别，数字识别的准确度和整体性能仍然保持不变。原因是在大多数情况下（例如数字3），这个数字在所有这些语言中具有相同的解释。因此，数字识别阶段在语言识别阶段误分类的情况下仍能正常执行。

为了验证语言识别模型对于字母相对类似的语言的影响，我们使用了两个阿拉伯语和波斯语数据库，有（和没有）语言识别模块来训练我们的数字识别模型。根据表8，在移除语言识别模型时，该模型的准确性降低了超过1％。这个结果再次强调了语言识别的重要作用。如果六种语言都没有使用语言识别，则由于类别数量的增加，性能会显著降低。

*** 4.3. 使用迁移学习的效应

正如第3节所提到的，我们使用英语数据库作为基准，通过迁移学习创建了自动编码器来增加图像分辨率。我们所提出的系统能够检测到低质量的小尺寸图像，并将其转发到迁移学习模块进行图像增强。在这里，我们以阿拉伯语数据库作为例子，该数据库具有28×28尺寸的低质量图像。如表9所示，如果我们将阿拉伯语数据库的图像大小调整为58×58，则所提出的CNN模型在该数据库上的准确度基本保持不变。然而，使用迁移学习技术后，所提出的CNN模型在阿拉伯语数据库上的准确度提高到了90％。英语和阿拉伯语数字图像的相似结构是将英语数据库用作自动编码器训练基准的主要原因。此外，英语手写数字图像的大尺寸以及可以使用下采样将其大小减小的能力也被视为使用英语数据库的另一个原因。如图2所示，中文数字的结构与英文或阿拉伯语数字的结构非常不同。因此，如果使用中文数据库来训练自动编码器以增加阿拉伯语数据库图像的分辨率，则CNN模型的准确度可能会降低。如表9所示，当自动编码器使用英语数据库进行训练时，所提出的CNN模型在阿拉伯语数据库上的准确度更高。同时，不使用迁移学习技术在英语和中文数据库上的原因是缺乏与这两个数据库具有相似结构的适当数据库。正如第3.1节所述，我们还创建了一组由英语、波斯语和阿拉伯语合成的数字图像，以进一步评估迁移学习对图像质量增强的有效性。这个合成数据集用于训练自动编码器。为了比较，我们计算了阿拉伯数字识别在自动编码器使用三个不同数据库训练（中文、合成和英文）时的准确度。这个实验的结果见表10。根据这个表格，当使用合成图像代替中文手写体时，准确度略有提高。然而，这仍然低于使用英文手写数字数据库训练的自动编码器的准确度。我们认为这种微小差异是由于手写数字和合成数字的不同结构造成的。同时，这个实验的结果支持了采用迁移学习进行图像质量增强时获得的性能提升。

除了用于增加阿拉伯语数据库图像质量的迁移学习技术外，我们还将同样的方法用于波斯语、乌尔都语和卡纳达语数据库中，对应的图像大小仅为28×28。我们使用训练了英文数据库的同一自动编码器来处理其他数据库。如表11所示，所提出的使用迁移学习技术的方法在这些数据库上的准确度均比LeNet模型高。值得一提的是，我们对不同的数据库进行了基准测试和训练我们的迁移学习模型，并发现英语数据库的性能最佳。

*** 4.4. 比较性能

在本小节中，我们比较了我们所提出模型与其他相关方法的性能。正如第3节中所提到的，我们使用了六个可用数据库来评估我们模型的性能。然而，我们的大多数评估都集中在阿拉伯语数据库上（由于低分辨率图像）以基于最坏情况下获取模型参数。表12显示了10000个阿拉伯语数据库测试数据的混淆矩阵。正确和错误预测的数量以每个类别的分解数字的百分比给出。精度和召回率的度量计算为：

其中，Mii表示表12中对应于第i类的第i个对角线元素。Mij和Mji分别是上三角和下三角的非对角线元素。如图2b所示，阿拉伯手写数字中数字0的形状与1和5非常相似。因此，这三个数字的精度低于其他数字。另外，数字2与3的相似性导致数字2被错误地识别为类别数字3。接下来，我们将所提出模型的性能与其他相关技术进行比较，尤其是基于深度学习的模型。如表13所示，我们在此实验中获得了三种字典学习方法（SRC [44]、DPL（字典对学习）[45]和InDPL（不相干字典对学习）[27]）、三个CNN模型（LeNet-5 [46]、VGG16 [47]、ResNet101 [48]）和带有和不带有迁移学习的所提出模型的结果。在所有这些方法中，所提出的模型具有最高的准确度。此外，VGG16显示出最接近所提出模型的准确度。VGG或ResNet表现更低的主要原因是，这些模型是利用大尺寸自然图像预先训练的，主要用于目标检测任务，而不是用于小尺寸手写数字图像的分类。我们还使用所提出模型测试了另一个阿拉伯手写数据库HAND2020。根据表14，原来HAND2020研究中提出的CNN模型已经实现了99.76％的识别准确度[43]。要达到这个准确度，他们的模型训练了850个周期。然而，正如在这个表格中看到的，我们提出的模型仅在10个周期后就已经实现了优越的性能。我们认为，针对不同语言精确地调整参数，并使用语言识别模块在提出的模型上使用，对于获得更高的性能具有重要影响。我们还在中文和英文数据库上测试了所提出的模型，以进一步评估模型的性能。如表15和表16所示，所提出的模型在所有方法中具有最高的准确性，表明了我们模型的高效性。




** 结论：

本文提出了一种多语言手写数字识别方法。该系统由两个主要模块组成：语言识别和数字识别。在这种基于卷积神经网络(CNN)的创新方法中，我们的系统首先识别输入图像的语言，然后决定最佳的模型参数来识别数字。此外，我们提出了使用迁移学习来统一来自不同数据库的图像质量。这允许在各种手写语言中实现稳健和一致的性能。我们进行了大量实验来调整和优化参数，以实现卓越的性能。我们对六种不同语言的实验结果表明，在与其他相关技术的比较中，我们的识别准确率高，即使与基于CNN结构的方法相比也是如此。本模型中利用迁移学习是实现卓越性能的主要原因之一，与之前的模型（如[43]）相比。此外，在我们的模型中，针对不同语言进行精确调整的参数对实现高识别准确性具有重大影响。未来的工作，我们计划将该模型扩展到识别多语言手写字符（字母）。此外，我们尝试开发一种设置一个系统来查找最佳超参数、层数、最小计算负担的过程。





